# Архитектурное ревью по моделям и сервисам RAG-цепочки

## Общая цепочка данных
- Пользователь взаимодействует с Telegram-ботом, который авторизуется в API базы знаний и отправляет файлы/команды через HTTP.
- API базы знаний загружает файлы в S3/MinIO и регистрирует события `knowledge_events` со статусом `new`, которые снимает Document Processor.
- Document Processor разбирает файлы, создаёт чанки, маркирует задачу на эмбеддинги (`embedding_generation=pending`), затем обогащает данными LLM.
- Отдельный universal_embedder может подхватить генерацию/обновление векторов и статусов, если встроенный воркер не используется.
- Поисковый API строит ответы на основе чанков с эмбеддингами, опционально добавляя графовый контекст, реранкер и историю диалога.

## knowledge_base_api
- Роль входной точки и очереди: сервис принимает файлы/метаданные, кладёт бинарники в S3/MinIO и создаёт событие `created` со статусом `new` в `knowledge_events`, обеспечивая версионирование и мягкое удаление через новые события/UUID. Это создаёт чёткое разделение между пользовательским вводом и внутренней обработкой.
- Риск согласованности статусов: в текущем ревью отмечено, что события удаления наследуют статус предыдущего события вместо `new`, из-за чего Deletion worker Document Processor не срабатывает. События должны принудительно маркироваться `status='new'` при удалении.

## document-processor
- Микросервис с тремя воркерами (`upload`, `enrichment`, `deletion`), работающими параллельно и управляемыми через таблицу событий/статусов. Он обеспечивает мульти-тенантность, версионирование, soft-delete, гибридный индекс (pgvector + tsvector) и опциональную выгрузку в граф Neo4j.
- Архитектура изолирует тяжёлое обогащение в отдельный конвейер, сохраняя статусную модель `enrichment_status.embedding_generation`, что позволяет внешним эмбеддерам работать согласованно.
- Требуется унификация ключей статусов с universal_embedder (`embedding_generation` вместо устаревшего `embedding_task`) для предотвращения повторной обработки.

## universal_embedder
- Асинхронный воркер, который сканирует таблицу `chunks`, выбирает записи без эмбеддингов или с устаревшей версией и генерирует батчи векторов локально или через OpenAI‑совместимый API. Умеет работать на GPU/DirectML/CPU и управляет кэшем моделей с автоматическим выгрузом.
- Дублирует часть логики Document Processor (статус-менеджмент, выбор модели, pooling), поэтому критично поддерживать единый формат статуса `enrichment_status.embedding_generation` и версионирование эмбеддингов, иначе воркеры будут гоняться за одними и теми же задачами.

## embedding_service
- Отдельный FastAPI для получения эмбеддингов по запросу, с раздельными эндпоинтами CPU/GPU. Использует менеджер моделей с кэшированием, блокировками и фоновым чистильщиком, способным грузить как SentenceTransformer, так и чистые Transformers модели.
- Сервис подходит для онлайн-коллбеков (например, пересчёта векторов под конкретную модель), но функционально пересекается с universal_embedder. Нужна договорённость, кто отвечает за продакшн-обновление эмбеддингов, чтобы избежать двойной нагрузки на БД.

## knowledge-search-api
- При старте инициализирует подключения к PostgreSQL и (опционально) Neo4j, поднимает SentenceTransformer для поиска и CrossEncoder как реранкер. Поддерживает режимы dense/BM25/hybrid, умеет строить графовый контекст и стримить ответы.
- Наличие fallback-ответа с прямыми цитатами и верификация ссылок повышают устойчивость к сбоям LLM, но требуют актуальности эмбеддингов и истории диалога; отсутствие векторов приводит к раннему возврату пустого ответа, поэтому синхронизация с Document Processor и universal_embedder критична.

## knowledge_base_bot
- Бот правильно оборачивает JWT и маршрутизирует команды, но архитектурно зависит от того, что API поддерживает поиск по UUID. В ревью обнаружено, что кнопки действий используют `/items/search` вместо прямого `get-by-id`, что ломает сценарий при UUID-запросах и создаёт зависимость от текстового поиска. Требуется контрактный эндпоинт по UUID.
- Управление жизненным циклом HTTP-клиентов отсутствует; для устойчивой работы бота нужны хуки запуска/остановки с закрытием клиентов, иначе возможны утечки соединений.

## Пересекающиеся риски и рекомендации
- **Единый формат статуса обогащения.** Все сервисы, работающие с чанками (Document Processor, universal_embedder), должны читать и обновлять `enrichment_status.embedding_generation` и `embedding_version`, иначе задачи дублируются.
- **Явные операции для UUID.** Внешние клиенты (бот, UI) должны иметь прямой вызов `get-by-id`, чтобы не зависеть от частичного текстового поиска и не ломать сценарии управления элементами.
- **Разделение ответственности по эмбеддингам.** Нужна явная зона ответственности: либо Document Processor закрывает задачу embeddings end-to-end, либо universal/embedder-service берёт на себя реобновление, чтобы не перегружать БД и не держать дублирующиеся кэши моделей.
