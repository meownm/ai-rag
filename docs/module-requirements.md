# Требования по модулям и их вызовы

Ниже собраны функциональные требования и ожидания по основным сервисам в цепочке «Telegram-бот → База знаний → Document Processor → Эмбеддер», включая направления вызовов.

## Telegram-бот (knowledge_base_bot)
* **Кто вызывает:** пользователь через Telegram; бот вызывает API базы знаний.
* **Цель:** принимать файлы/команды, валидировать ввод и проксировать операции в API базы знаний с корректным `item_uuid`.
* **Требования:**
  * Обновлять и прокидывать JWT для всех запросов (`/token`, затем Bearer) перед отправкой в API базы знаний.
  * При загрузке файла скачивать бинарные данные из Telegram и отправлять их как `POST /files`.
  * Для действий по уже известному `item_uuid` обращаться к API, которое принимает UUID (а не поиск по имени), чтобы кнопки управления работали детерминированно.
  * Обрабатывать ответы API и сообщать пользователю статус (создано, удалено, ошибка), не дублируя запросы при ошибках сети.

## API базы знаний (knowledge_base_api)
* **Кто вызывает:** Telegram-бот и внутренние админ-инструменты.
* **Цель:** хранить метаданные/файлы, ставить события в очередь для обработки Document Processor и возвращать статус элементов.
* **Требования:**
  * `POST /files` принимает бинарный файл, сохраняет его в S3/MinIO и создаёт событие в `knowledge_events` со статусом `new` и операцией `created` для Document Processor.
  * Повторная загрузка помечает старую версию элемента как `DELETED`, выдаёт новый `item_uuid` и регистрирует новое событие.
  * Удаление (`/items/{uuid}`) создаёт событие с операцией `deleted` и **обязательно** со статусом `new`, чтобы попало в очередь Document Processor.
  * Предоставляет операции чтения (`/items`, `/items/search`, `/status`) и прямой доступ по `item_uuid`, чтобы клиенты не полагались на поиск по имени.

## Document Processor (document-processor)
* **Кто вызывает:** читает события из таблицы `knowledge_events`, созданные API базы знаний.
* **Цель:** забрать новые или удалённые элементы, распарсить файлы, сформировать чанки и управлять статусом обогащения.
* **Требования:**
  * Воркер загрузки обрабатывает события `created` со статусом `new`: скачивает файл из хранилища, парсит, чанкует и пишет в `documents`/`chunks`, устанавливая `enrichment_status.embedding_generation = pending`.
  * Воркер удаления обрабатывает события `deleted` со статусом `new`: удаляет документы/чанки и связанные узлы в графе (если подключён Neo4j).
  * Воркер обогащения обрабатывает чанки со статусом `embedding_generation = pending`: вычисляет эмбеддинги (локальная модель или внешний API), обновляет `chunks.embedding`, закрывает статус в `completed` и фиксирует `embedding_version`.
  * Формат статуса обогащения должен быть единым (`enrichment_status.embedding_generation`) для совместимости с внешним эмбеддером.

## Универсальный эмбеддер (universal_embedder)
* **Кто вызывает:** периодически сканирует БД, куда пишет Document Processor; не вызывается напрямую ботом.
* **Цель:** альтернативно генерировать/обновлять эмбеддинги для чанков при наличии новой версии модели или отсутствии вектора.
* **Требования:**
  * Пуллит батчи из таблицы `chunks`, где нет эмбеддинга или версия устарела, и ставит локальный блокировку/версию на время работы.
  * Вычисляет эмбеддинги локальной моделью или через OpenAI-совместимый API, массово обновляет `chunks.embedding` и `embedding_version`.
  * Обновляет поле статуса в согласованном формате (`enrichment_status.embedding_generation`) чтобы не дублировать работу с Document Processor.

## Поисковый API (knowledge-search-api)
* **Кто вызывает:** клиенты (включая бот) для поиска/генерации ответов после обработки документов.
* **Цель:** предоставлять гибридный поиск и генерацию ответа, используя чанки с готовыми эмбеддингами.
* **Требования:**
  * Инициализировать подключение к PostgreSQL (и опционально Neo4j) при старте, быть готовым к параллельным запросам.
  * Ожидать, что `chunks.embedding` заполнен и содержит актуальную версию; отсутствие эмбеддингов должно обрабатываться как пропуск чанков.
  * Предоставлять API `/v1/answer` для гибридного поиска, поддерживать графовый контекст при наличии Neo4j и корректно стримить ответы клиента.
  * Корректно учитывать историю диалога только один раз в промпте для управления затратами токенов.
