{"title": "LLM Usage (per model)", "templating": {"list": [{"name": "service", "type": "query", "datasource": "Prometheus", "query": "label_values(llm_latency_seconds_count, service)", "refresh": 2}, {"name": "model", "type": "query", "datasource": "Prometheus", "query": "label_values(llm_latency_seconds_count, model)", "refresh": 2}]}, "panels": [{"type": "timeseries", "title": "Calls per minute", "targets": [{"expr": "sum by (service,model) (rate(llm_latency_seconds_count[1m]))"}]}, {"type": "timeseries", "title": "Latency p90 by model", "targets": [{"expr": "histogram_quantile(0.9, sum by (model,le) (rate(llm_latency_seconds_bucket[5m])))"}]}, {"type": "bargauge", "title": "Tokens by model (5m)", "targets": [{"expr": "sum by (model) (increase(tokens_total[5m]))"}]}], "schemaVersion": 38, "version": 1}