# Document Processor Service (Internal Worker)

**Версия: 3.2.0**

Этот сервис представляет собой мощный **внутренний бэкенд-компонент**, предназначенный для построения многопользовательских (multi-tenant) систем **Retrieval-Augmented Generation (RAG)**. Он работает как асинхронный конвейер, который получает задачи на обработку документов, извлекает из них структурированные и неструктурированные данные, обогащает их с помощью LLM и индексирует для последующего поиска.

Сервис спроектирован как **микросервис** в более крупной экосистеме, принимая задачи от внешнего API Gateway, который отвечает за работу с пользователями.

## Ключевые возможности

*   **Multi-Tenancy:** Полная изоляция данных по "арендаторам" (`tenant_id`) на всех уровнях: PostgreSQL, MinIO и Neo4j.
*   **Управление жизненным циклом:**
    *   **Версионирование:** Поддержка нескольких версий одного документа с сохранением полной истории.
    *   **Мягкое удаление (Soft Delete):** Документы помечаются как удаленные, а не стираются физически, с возможностью восстановления.
*   **Специализированные воркеры:** Асинхронная обработка разделена на независимые, параллельно работающие потоки (`upload`, `enrichment`, `deletion`) для максимальной производительности и отказоустойчивости.
*   **Асинхронное обогащение:** "Дорогие" LLM-операции (извлечение метаданных, графа знаний) вынесены в отдельный конвейер и управляются через статусную модель, не блокируя основную индексацию.
*   **Поддержка множества форматов:** Обрабатывает `.docx`, `.pdf`, `.pptx`, `.txt`, `.html`, `.xml`, `.json`, `.csv`, `.xls`, `.xlsx`, `.md` и другие через Pandoc.
*   **Умный Чанкинг:** Сохраняет иерархическую структуру документа (главы, разделы) в метаданных каждого чанка.
*   **Гибридный Поиск:** Готовит данные для гибридного поиска, сохраняя векторные эмбеддинги (`pgvector`) и полнотекстовые векторы (`tsvector`) в PostgreSQL.
*   **Граф Знаний:** Извлекает **типизированные** сущности и отношения и строит семантическую сеть в Neo4j.
*   **Универсальная поддержка LLM:** Работает с **Ollama**, **LM Studio** и другими OpenAI-совместимыми API.
*   **Production-Ready:**
    *   **Надежность:** Автоматический перезапуск воркеров при сбоях и ретраи для сетевых запросов.
    *   **Управляемость:** Корректное "вежливое" завершение работы (Graceful Shutdown).
    *   **Мониторинг:** Встроенные метрики для **Prometheus** (`/metrics`) и детальный **Health Check** (`/health`).
    *   **Централизованное логирование:** Все события пишутся в консоль и ротируемые файлы.

## Архитектура системы

Сервис является **внутренним обработчиком** и не предназначен для прямого взаимодействия с конечными пользователями. Он получает задачи от внешнего **API Gateway**.

```mermaid
graph TD
    subgraph "Внешний мир"
        User[Пользователь] -- Загружает файл --> APIGateway[API Gateway]
    end

    subgraph "Инфраструктура"
        MinIO[MinIO Storage]
        DB[(PostgreSQL)]
        Neo4j[Neo4j Graph DB]
        LLM[LLM Service]
        Prometheus
    end

    subgraph "Document Processor Service (Наш сервис)"
        FastAPI[FastAPI App] -- Предоставляет --> Health[/health] & Metrics[/metrics]
        FastAPI -- Запускает и управляет --> Workers
        
        subgraph "Специализированные Воркеры (Потоки)"
            Workers
            UploadWorker[Upload Worker]
            EnrichWorker[Enrichment Worker]
            DeleteWorker[Deletion Worker]
        end
    end

    APIGateway -- 1. Кладет файл --> MinIO
    APIGateway -- 2. Создает задачу в `knowledge_events` --> DB
    
    UploadWorker -- 3. Ищет задачи 'process_new_version' --> DB
    UploadWorker -- 4. Обрабатывает и индексирует --> MinIO & DB
    
    EnrichWorker -- 5. Ищет чанки со статусом 'pending' --> DB
    EnrichWorker -- 6. Обогащает данные --> LLM & DB & Neo4j
    
    DeleteWorker -- 7. Ищет задачи 'deprovision_deleted' --> DB
    DeleteWorker -- 8. Очищает данные --> MinIO & Neo4j
    
    Prometheus -- Скрейпит --> Metrics
```

## Установка и запуск

### 1. Предварительные требования
*   **Docker** и **Docker Compose**
*   **Python 3.10+**
*   **Poetry**

### 2. Запуск внешних сервисов
Используйте `docker-compose.yml` для запуска PostgreSQL, MinIO и Neo4j. Убедитесь, что ваш `.env` файл заполнен корректными значениями.
```bash
# Заполните .env файл перед запуском
docker-compose up -d
```
После запуска MinIO, создайте в нем бакет, указанный в `MINIO_BUCKET_NAME`.

### 3. Установка сервиса
1.  **Клонируйте репозиторий.**
2.  **Настройте конфигурацию:** Скопируйте `.env.example` в `.env` и заполните все поля.
3.  **Установите зависимости:**
    ```bash
    poetry install
    ```

## Конфигурация (`.env`)
Все параметры сервиса управляются через `.env` файл. Ключевые новые параметры:
| Переменная | Описание | Пример |
| --- | --- | --- |
| `UPLOAD_WORKER_COUNT` | Количество потоков для обработки новых документов. | `2` |
| `ENRICHMENT_WORKER_COUNT`| Количество потоков для обогащения данных через LLM. | `1` |
| `DELETION_WORKER_COUNT`| Количество потоков для обработки задач на удаление. | `1` |
| `JWT_SECRET_KEY` | (Не используется) Секретный ключ для JWT. | `your-secret` |

## Запуск сервиса
```bash
poetry run uvicorn main:app --host 0.0.0.0 --port 8010
```

## Контракт взаимодействия (Требования к API Gateway)

Этот сервис ожидает, что внешний API Gateway будет выполнять следующие действия:

#### 1. Создание нового документа
1.  Сгенерировать **новый** `conceptual_doc_id` (UUID).
2.  Сгенерировать **новый** `doc_id` (UUID) для первой версии.
3.  Выполнить `INSERT` в таблицу `documents` с `version = 1`, `is_latest = true`, а также `tenant_id` и `owner_user_id` из контекста пользователя.
4.  Загрузить файл в MinIO по пути `/<tenant_id>/<doc_id>/<filename>`.
5.  Создать задачу в `knowledge_events` с `operation = 'process_new_version'`, `item_uuid = <doc_id>`, и `status = 'new'`.

#### 2. Обновление документа (создание новой версии)
1.  Найти `version` старой "последней" версии по `conceptual_doc_id`.
2.  В одной транзакции:
    *   `UPDATE documents SET is_latest = false` для старой версии.
    *   `INSERT` новую запись в `documents` с тем же `conceptual_doc_id`, `version = старая_версия + 1`, `is_latest = true` и **новым `doc_id`**.
3.  Загрузить новый файл в MinIO по пути `/<tenant_id>/<новый_doc_id>/<filename>`.
4.  Создать задачу в `knowledge_events` с `operation = 'process_new_version'`, `item_uuid = <новый_doc_id>`, и `status = 'new'`.

#### 3. Мягкое удаление документа
1.  Выполнить `UPDATE documents SET deleted_at = NOW(), deleted_by_user_id = <user_id>` для всех версий, принадлежащих `conceptual_doc_id`.
2.  Создать задачу в `knowledge_events` с `operation = 'deprovision_deleted'`, `item_uuid = <conceptual_doc_id>`, и `status = 'new'`.

## API Справка (Служебные эндпоинты)

### `GET /health`
Детальная проверка состояния всех зависимостей. Возвращает `200 OK` если все в порядке, и `503 Service Unavailable` если есть проблемы.

### `GET /metrics`
Эндпоинт для сбора метрик системой мониторинга Prometheus.